{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a95462-127d-48d4-89a6-6d39f8aea72c",
   "metadata": {},
   "source": [
    "## <div align='center'><h1><span style=\"font-size: 2em;\"><font color=\"blue\">Projet:Credit_Card_Fraud</font></span></h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bde5cd-b099-4ed5-9de1-836fdf0fc063",
   "metadata": {},
   "source": [
    "#### <div align='center'><h1><span style=\"font-size: 1em;\"><font color=\"red\">Réalisé par : Boubacar Zeidan (ESBD) </font></span></h1></div>\n",
    "#### <div align='center'><h1><span style=\"font-size: 1em;\"><font color=\"red\">Encadré par :  Pr. B . BENYACOUB </font></span></h1></div>\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5398c2bc-ada2-4bb3-b54d-e0e604745f97",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Contexte de l'étude :</font>\n",
    "\n",
    "Dos nos jours, les fraudes par carte de crédit sont des cibles faciles et conviviales. Il est important que les banques et les organismes financiers qui délivrent les cartes de crédit soient en mesure de reconnaître les transactions frauduleuses par carte de crédit afin que les clients ne soient pas facturés pour les articles qu'ils n'ont pas achetés. Le commerce électronique à travers les sites en ligne a augmenté les modes de paiement en ligne et le risque de fraudes en ligne se pose comme une problématique intéressante pour l’étudier. D’où la nécessité de mise en place d’un modèle de prédiction a pour objectif identifié les fraudes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ab50a-bc96-4399-9fd1-509063f7cda5",
   "metadata": {},
   "source": [
    "## 1-Prétraitement des données :\n",
    "Pour garantir l'intégrité de notre analyse, nous avons d'abord vérifié la présence de valeurs manquantes dans notre ensemble de données. Si des valeurs manquantes étaient détectées, nous les avons traitées de manière appropriée pour éviter toute influence indue sur nos résultats. Nous avons opté pour l'imputation en remplaçant les valeurs manquantes par la médiane des données disponibles.\n",
    "## 2-Équilibrage des données :\n",
    "Comme l'ensemble de données est très déséquilibré, utilisez des techniques de suréchantillonnage pour équilibrer les classes. \n",
    "## 3-Division des données :\n",
    "Divisez l'ensemble de données en un ensemble d'apprentissage et un ensemble de test.  on réserve environ 80 % des données pour l'apprentissage et le reste pour le test.\n",
    "## 4-Construction des modèles de classification :\n",
    "j'utilise différents algorithmes de classification supervisée tels que la régression logistique, les arbres de décision, les forêts aléatoires, etc.\n",
    "Entraînez ces modèles sur l'ensemble de données d'apprentissage équilibré.\n",
    "## 5-Évaluation des modèles :\n",
    "Évaluez les performances de chaque modèle en utilisant des mesures appropriées telles que la précision, le rappel, le score F1, etc., sur l'ensemble de test.\n",
    "Comparez les performances des différents modèles pour voir lequel fonctionne le mieux pour l'ensemble de données.\n",
    "## 6-Optimisation des hyperparamètres (facultatif) :\n",
    "effectuez une recherche d'hyperparamètres pour optimiser les performances des modèles sélectionnés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e95a9b-47ed-477a-ad6d-ad118357b978",
   "metadata": {},
   "source": [
    "# 0-Importez les librairies usuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d8c703-f768-486b-a108-e3e847b99e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c4b76-1740-497a-af10-892ec3e6a94b",
   "metadata": {},
   "source": [
    "# 1-Prétraitement des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03df6d62-b672-484f-bd3a-9c3c6b81633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Class  Amount_bin  \n",
      "0 -0.189115  0.133558 -0.021053      0           1  \n",
      "1  0.125895 -0.008983  0.014724      0           0  \n",
      "2 -0.139097 -0.055353 -0.059752      0           3  \n",
      "3 -0.221929  0.062723  0.061458      0           1  \n",
      "4  0.502292  0.219422  0.215153      0           0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données\n",
    "df = pd.read_csv(\"C:/Users/hp/Desktop/INSEA-S4/Apprentisage_non sup & sup 2024/Credit_Card_Fraud/Credit_Card_Fraud/creditcard.csv\")\n",
    "\n",
    "# Vérification des valeurs manquantes\n",
    "print(df.isnull().sum())\n",
    "# Discrétisation de la variable 'Amount'\n",
    "bins = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "labels = list(range(len(bins)-1))\n",
    "df['Amount_bin'] = pd.cut(df['Amount'], bins=bins, labels=labels)\n",
    "\n",
    "# Suppression de la colonne 'Amount' originale\n",
    "df.drop('Amount', axis=1, inplace=True)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea9e3a-8529-400f-be36-02ed49a4bc3f",
   "metadata": {},
   "source": [
    "# 2-Équilibrage des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e124178-0524-4db0-9750-1d3f59e139e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1    284315\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Définition des variables indépendantes (X) et dépendante (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Imputation des valeurs manquantes avec la médiane\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Suréchantillonnage avec SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
    "\n",
    "# Création d'un nouveau DataFrame pour les données équilibrées\n",
    "balanced_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "balanced_df['Class'] = y_resampled\n",
    "\n",
    "print(balanced_df['Class'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc78ea-c191-41d3-a11e-c429170988ce",
   "metadata": {},
   "source": [
    "# 3-Division des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ce30e2-79c0-4a1d-bb1d-0d2dcdb4ea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'apprentissage : 454904\n",
      "Taille de l'ensemble de test : 113726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Division des données équilibrées en ensemble d'apprentissage et ensemble de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_df.drop('Class', axis=1), balanced_df['Class'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Taille de l'ensemble d'apprentissage :\", len(X_train))\n",
    "print(\"Taille de l'ensemble de test :\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743d564-1506-4783-8282-5c0e87356f3f",
   "metadata": {},
   "source": [
    "# 4-Construction des modèles de classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510a443-43f3-4231-a589-ac9eeecad432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialisation des modèles\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Entraînement des modèles\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# 5. **Évaluation des modèles** :\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033be9e-054e-41d2-bcc8-7e5904f42854",
   "metadata": {},
   "source": [
    "# 5-Évaluation des modèles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb1b63e1-8f32-4e54-b840-b298eaff6e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     56750\n",
      "           1       0.98      0.97      0.98     56976\n",
      "\n",
      "    accuracy                           0.98    113726\n",
      "   macro avg       0.98      0.98      0.98    113726\n",
      "weighted avg       0.98      0.98      0.98    113726\n",
      "\n",
      "--- Decision Tree ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56750\n",
      "           1       1.00      1.00      1.00     56976\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "--- Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56750\n",
      "           1       1.00      1.00      1.00     56976\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fonction pour l'évaluation des modèles\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"--- {name} ---\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Appel de la fonction pour évaluer les modèles\n",
    "evaluate_models(models, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c815e2-8e5c-463b-9b28-b72ccc9a8f6f",
   "metadata": {},
   "source": [
    "# 6-Optimisation des hyperparamètres (facultatif) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235caa1-3fec-4a98-be52-ee02ab23f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définition des hyperparamètres à optimiser pour chaque modèle\n",
    "param_grid = {\n",
    "    'Logistic Regression': {'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    'Decision Tree': {'max_depth': [None, 10, 20, 30, 40, 50]},\n",
    "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30, 40, 50]}\n",
    "}\n",
    "\n",
    "# Initialisation de GridSearchCV pour chaque modèle\n",
    "grid_searches = {}\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid[name], cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    grid_searches[name] = grid_search\n",
    "\n",
    "# Affichage des meilleurs paramètres pour chaque modèle\n",
    "for name, grid_search in grid_searches.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "\n",
    "# Sélection des meilleurs modèles après optimisation\n",
    "best_models = {name: grid_search.best_estimator_ for name, grid_search in grid_searches.items()}\n",
    "\n",
    "# Évaluation des meilleurs modèles sur les données de test\n",
    "print(\"\\n--- Évaluation des meilleurs modèles sur les données de test ---\")\n",
    "evaluate_models(best_models, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7421485-61b2-4216-b5cc-4cb63b207175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
